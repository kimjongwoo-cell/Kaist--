INTRODUCTION
Knowledge Tracing은 학생의 문제(exercise) 혹은 문제의 개념(Knowledge concept)의 지식의 정도(knowledge state)가 시간에 따라 어떻게 변화하는지, 다음 문제를 맞출 수 있을지 없을지 예측하는 Task입니다. 예를 들어 산타토익과 같은 문제 풀이 앱을 활용할 때 기존 사용자가 푼 문제 1~6를 학습해 사용자의 학습 수준을 유추하고 이를 활용하여 문제 7,8,9,10의 정오답을 예측하는 것입니다. 

MOTIVATION 
본 논문에서 한계점으로 지적하는 부분은 이전 논문들은 모두 성능을 향상시키는 데만 집중하고, 높은 성능을 보이는 곳은 문제의 개념(Knowledge concept)의 지식의 정도(knowledge state)를 잘 추정할 수 있다는 가정을 가지고 있습니다. 하지만 모델의 성능을 향상시키는 데에만 치중하면 학생의 지식과 학습 과정 사이의 불일치를 초래할 수 있습니다. 
학생의 지식과 학습 과정 사이의 불일치는 두 가지가 존재합니다. 이해를 돕기 위해 Figure 1을 보겠습니다.
1.	학생이 문제를 틀리면 해당 개념에 대한 지식이 없다고 판단하여knowledge state가 감소합니다. 예를 들면, KC2에 대한 knowledge state가 e4 문제를 풀 때 0.74이었는데, e5 문제를 틀렸을 때 0.69으로 감소하는 것을 볼 수 있습니다. 그러나 실제로는 문제를 틀렸다고 해서 해당 학생의 지식이 반드시 감소하는 것은 아닙니다. 
2.	KC와 관련이 없는 문제를 풀었지만, KC의 knowledge state가 감소한 경우도 있습니다. 예를 들면, e1~e4는 모두 KC1과 관련된 문제이지만 KC2과 KC3의 knowledge state가 업데이트됩니다. 그러나 실제로는 Absolute Value와 관련된 문제를 푼다고 해서 Ordering Integers의 지식이 학습되지는 않습니다. 
3.	
본 논문은 지식 추적(Knowledge Tracing) 문제를 해결하기 위해 학생들의 학습 과정을 직접 모델링하는 새로운 패러다임을 제시합니다. 이를 위해서는 학생들의 학습 과정을 정의하고 모델링하기 위한 적절한 형태로 변환하는 방법, 학습 효과를 측정하는 방법, 지식 상태의 감소도 고려하는 방법 등 다양한 문제가 존재합니다. 따라서 LPKT라는 새로운 방법론을 제시하고 이를 통해 기존 방법들보다 더 합리적이고 해석 가능한 지식 상태 추적 결과를 얻을 수 있다는 것을 실험을 통해 입증하였습니다.

METHOD
PRELIMINARY 
LPKT의 몇 가지 중요한 임베딩을 제시합니다. 학습 프로세스는 연속된 문제 풀이 행동을 반복하며, 연속된 행동 간에는 간격이 있습니다. 따라서 학생의 학습 과정은 
x = {(e_1, 〖at〗_1, a_1),〖it〗_1, (e_2, 〖at〗_2, a_2),〖it〗_2, …,(e_t, 〖at〗_t, a_t),〖it〗_t } 
와 같은 학습 순서로 표시됩니다. 여기서 e_t, 〖at〗_t, a_t 튜플은 기본 학습 셀을 나타내며  

	e_t는 연습 문항 
	〖at〗_t는 학생이 e_t을 대답하는 데 사용한 시간 (문제 푸는 시간) 
	a_t은 이진 정확성 레이블 (1은 맞고 0은 틀린것) 
	〖it〗_t는 학습 셀 간의 간격 시간 (다음 문제를 풀기 까지 걸린 시간)

KT 작업은 학생의 학습 과정에서 지식 상태의 변화를 모니터링하고, 다음 학습 단계 t + 1에서 학생의 미래 성과를 예측하는 것을 목표로합니다. 이는 개별화된 학습 방식을 적용하고 학습 효율성을 극대화하는 데 사용될 수 있습니다. 

Embedding  
	Time Embedding 
시간 임베딩은 학생들의 학습 과정에서 중요한 역할을 하는 답변 시간과 간격 시간을 임베딩하는 것을 의미한다. LPKT에서는 간격 시간이 답변 시간보다 훨씬 길기 때문에 전자는 분 단위로 후자는 초 단위로 이산화하고, 1개월 이상의 간격 시간은 1개월로 설정한다. 

	Learning Embedding 
연습 문항 집합을 임베딩 행렬로 표현하고, 각각의 연습 문항과 답변 시간, 답변을 합쳐서 학습 임베딩을 만드는 방법을 제안하고 있다

l_t  = W_1   [e_t⊕ 〖at〗_t  ⊕ a_t] + b_1
	Knowledge Embedding 
LPKT에서는 학생의 학습 과정에서 학생의 지식 상태를 저장하고 업데이트하는 지식 임베딩이 사용됩니다. 지식 임베딩은 지식 개념의 수에 해당하는 M x dk 차원의 임베딩 행렬 h로 초기화됩니다. 학습 상호작용마다 LPKT가 모델링하는 각 지식 개념에 대한 학습 이득이 지식 임베딩에 업데이트되며, 동시에 지식 상태의 잊어버림 효과도 포함됩니다. Q-행렬은 연습 문제와 지식 개념 간의 관계를 나타내며, 해당 연습 문제를 푼 후 지식 임베딩의 해당 행이 업데이트됩니다. 오류와 주관적 편향성이 불가피하므로, 우리는 새로운 행렬 q를 도입하여 이를 보완합니다.

Figure 2와 같이, LPKT는 각 학습 단계에서 세 가지 모듈로 구성됩니다: (1) 학습 모듈, (2) 잊어버리기 모듈, (3) 예측 모듈. 구체적으로, 학생이 연습문제에 대답한 후, 학습 모듈은 이전 학습 상호작용과 비교하여 학습 효과를 모델링합니다. 잊어버리기 모듈은 시간이 지남에 따라 얼마나 많은 지식이 잊혀질지를 측정하는 데 사용됩니다. 그런 다음, 학습 효과와 잊혀진 지식은 학생의 이전 지식 상태를 업데이트하기 위해 활용됩니다. 마지막으로, 예측 모듈은 학생의 최신 지식 상태에 따라 다음 연습문제에서의 성적을 예측하기 위해 제안됩니다.
Learning Module
학습 획득 모델링을 위해 학생의 이전 학습 임베딩 lt−1과 현재 학습 임베딩 lt을 연결하는 방식을 채택합니다. 그러나 두 연속적인 학습 임베딩으로 학생들의 성능 차이를 포착할 수 있지만, 학습 과정에서 학생들의 학습 획득 다양성을 포착할 수 없습니다. 예를 들어, 동일한 연속적인 학습 임베딩(즉, 겹치는 학습 시퀀스의 일부에서 동일한 성능을 가진)를 가진 학생들도 모두 동일한 학습 획득을 가지는 것은 아닙니다. 따라서, 우리는 LPKT에서 학습 획득의 두 가지 영향 요소를 고려합니다. 이것들은 간격 시간과 학생의 이전 지식 상태입니다. 한편, 두 학습 셀 간의 간격 시간은 학습 과정에서 중요한 요소이며, 학생들은 일반적으로 간격 시간이 짧을수록 더 많은 지식을 습득하므로, 그들의 학습 과정은 밀접하고 연속적이다는 것을 의미합니다.
, we frst multiply ht−1 and the knowledge concept vector qet of present exercise and get the related knowledge state het−1: het−1 = qet · ht−1,
lgt = tanh(WT 2 [lt−1 ⊕ itt ⊕ lt ⊕ het−1] + b2),
Γ l t = σ(WT 3 [lt−1 ⊕ itt ⊕ lt ⊕ het−1] + b3),
LGt = Γ l t · ((lдt + 1)/2), LGft = qet · LGt ,
LGft를 계산한 후, 학생들의 지식 상태에 강화된 역할을 하는 것으로, 시간이 지남에 따라 잊혀지는 현상이 지식이 얼마나 잊혀질지에 영향을 미친다. 잊혀짐 곡선 이론에 따르면[18], 학습한 자료 중 기억하는 양은 시간이 지남에 따라 지수 함수적으로 감소한다. 그러나 단순한 수작업 설계의 지수 감소 함수는 지식 상태와 간격 시간 간의 복잡한 관계를 캡처하기에 충분하지 않다. 복잡한 잊어버림 효과를 모델링하기 위해, 우리는 LPKT에서 잊어버림 게이트 Γf
t를 설계했는데, 이는 학생들의 세 가지 요인을 기반으로 지식 매트릭스에서 상실 정보의 정도를 학습하기 위해 MLP를 적용한다: (1) 학생들의 이전 지식 상태 ht−1, (2) 학생들의 현재 학습 획득 LGt, 그리고 (3) 간격 시간 itt이다.
Γ f t = σ(WT 4 [ht−1 ⊕ LGt ⊕ itt ]) + b4)
ht = LGft + Γ f t · ht−1.

Predicting Module
yt+1 = σ(WT 5 [et+1 ⊕ het ] + b5),

EXPERIMENT
CONCULSION
AUTHOR INFORMATION

REFERENCE
